{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i. Selection Bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To traing to test our code for performing analysis we select random sample set of data points. The sample data should be random to get best results but if while selecting sample data we become biased towards some criteria then our sample data is not completely random. This is called selection bias. We should avoid it to get best results from our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii. Power Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For any analysis we want to make sure that we have the right amount of sample data set for anaylsis. It should not be too small that we get incorrect analysis results and it shouldnt be too large so that it uses our resources or computational power too much. Power analysis is the study of how much data set would be optimum for our analysis, it is done before data collection stage, might be considered the very first step to be performed. The  right amount of sample set would be minimum number of data points for accurate result of analysis and thats what power analysis provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii. Good data or good models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having good models is more important than having good data because good models can cover up shortcomings of bad data whereas bad models wont give good results despite good data. In other words, one would get better results from good models and mediocre data rather than the results from bad models and good data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv. Number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Elbow Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method we start from one cluster and keep increasing number of clusters and while we do that we perform a mathematical equation for each number of clusters. We calculate the distance between the point and the cluster center and then calculate squared average of the distances. We then start plotting it against number of clusters. The graph would make an elbow and we select optimum cluster at the edge of the elbow or where graph start bending. If we choose before it, that means we underfit meaning we have choosen too little clusters and different data points would lie in same cluster. If we choose more than this then we overfit meaning we choose too much clusters and now even similar points have made clusters of their own."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sum of squares method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this method we use same technique of starting with two clusters and keep adding clusters but now we solve two equations, one for within clusters and one between clusters. We calculate sum of squares within a cluster and between cluster. As we keep adding clusters we keep noting the two values we want to determine. Our goal is to reach a cluster count where within cluster value in minimum and inter cluster value is maximum. This will mean that the points within clusters to strongly related to one another and there is sufficient difference between clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
